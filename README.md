# SENTIMENT ANALYSIS OF TEXT EMOTION ON TWITTER

Negation-aware Twitter preprocessing + classic ML baselines.  
Cleans tweets (URLs, @mentions, #hashtags, emojis, contractions, elongated words), **preserves negations**, then trains TF-IDF / Count models (LogReg, Linear SVM, Naive Bayes, Random Forest).  
Includes ROC curve (AUC), PR curve (optional), macro-F1/accuracy, and a saved scikit-learn **Pipeline**.

---

## âœ¨ Highlights
- Twitter-specific cleaning with optional POS-lemmatization
- No data leakage (vectorizers fit on **train** only; transform val/test)
- Metrics: **macro-F1**, accuracy, **ROC-AUC**, confusion @ Youdenâ€™s J
- Reproducible (`random_state=42`)
- Serialized model: `twitter_sentiment_pipeline.joblib`
- Tiny CLI for inference: `predict.py`

---

## ğŸ—‚ï¸ Dataset
- File: `text_emotion.csv`
- Columns used: `tweet_id`, `sentiment`, `content` (dropped `author`)
- Labels kept: **happiness** and **sadness** (others filtered out)

**Cleaning pipeline (short):**  
lower â†’ URL/@ tokens â†’ strip `rt` â†’ keep hashtag word â†’ `emoji.demojize` â†’ expand contractions â†’ compress elongations â†’ numbersâ†’`NUM` â†’ strip punct/whitespace â†’ (optional) POS-lemmatize â†’ remove stopwords **but keep negations**.

---

## âš™ï¸ Setup
```bash
python -m venv .venv
# Windows: .venv\Scripts\activate
source .venv/bin/activate

pip install -r requirements.txt
python - <<'PY'
import nltk
for x in ['stopwords','wordnet','omw-1.4','averaged_perceptron_tagger','vader_lexicon']:
    try:
        (nltk.data.find(f'taggers/{x}') if x=='averaged_perceptron_tagger' else nltk.data.find(f'corpora/{x}'))
    except LookupError:
        nltk.download(x)
PY
```
## ğŸš€ Train & Evaluate
Notebook
Open and run:
'18BCE2199_NLP_PROJECT_twitter_sentimental_analysis.ipynb'


Script (end-to-end)
'python 18bce2199_nlp_project_twitter_sentimental_analysis.py'


This trains with GridSearchCV, prints metrics, plots curves, and saves:
'twitter_sentiment_pipeline.joblib'

## ğŸ“ˆ Results (current run)
ROC-AUC (test): 0.889
Best held-out accuracy: ~0.80 (Count n-grams + Linear SVM)

![a](https://github.com/Kartikay77/Twitter-sentimental-analysis-snlp/blob/main/SNLP1.png)
![b](https://github.com/Kartikay77/Twitter-sentimental-analysis-snlp/blob/main/SNLP2.png)

## ğŸ”® Inference (CLI)
After a run has produced twitter_sentiment_pipeline.joblib:

python predict.py --model twitter_sentiment_pipeline.joblib \
  --text "I am very happy today! The atmosphere looks cheerful" \
  --text "This is quite depressing. I am filled with sorrow"

Example output:
[happiness] I am very happy today! The atmosphere looks cheerful
[sadness]   This is quite depressing. I am filled with sorrow

## ğŸ§° Tech Stack
Python, pandas, NumPy, matplotlib, scikit-learn, NLTK, emoji, contractions, joblib

## ğŸ§ª Baseline (optional)
Compare against VADER to show lift:
python baseline_vader.py
prints baseline accuracy and macro-F1 on happiness/sadness


## âš–ï¸ Notes & Ethics
Tweets can be noisy/biased; this model is for educational/demo purposes, not high-stakes decisions.


## ğŸ“œ License
Add a LICENSE file (e.g., MIT).
MARKDOWN
--- requirements.txt ---
cat > requirements.txt <<'REQ'
scikit-learn>=1.3
pandas>=1.5
numpy>=1.24
matplotlib>=3.7
nltk>=3.8
emoji==2.10.1
contractions>=0.1
joblib>=1.3
REQ




 
